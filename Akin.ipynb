{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sympy import Symbol, lambdify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Input/training.dat', sep=' ', header=None, names=['x', 'y']);\n",
    "test_data = pd.read_csv('Input/test.dat', sep=' ', header=None, names=['x', 'y']);\n",
    "\n",
    "x_train = np.array(train_data['x'])\n",
    "y_train = np.array(train_data['y'])\n",
    "\n",
    "w0 = Symbol(\"w0\")\n",
    "w1 = Symbol(\"w1\")\n",
    "w2 = Symbol(\"w2\")\n",
    "\n",
    "func_a = np.sum(np.square(y_train - w0 - w1 * x_train))\n",
    "f_a = lambdify([[w0, w1]], func_a, \"numpy\")\n",
    "gf_a = lambdify([[w0, w1]], func_a.diff([[w0, w1]]), \"numpy\")\n",
    "grad_fa = lambda x_arr : np.array(gf_a(x_arr), 'float64').reshape(1,len(x_arr))\n",
    "\n",
    "func_b = np.sum(np.square(y_train - w0 - w1 * x_train - w2 * x_train**2))\n",
    "f_b = lambdify([[w0, w1, w2]], func_b, \"numpy\")\n",
    "gf_b = lambdify([[w0, w1, w2]], func_b.diff([[w0, w1, w2]]), \"numpy\")\n",
    "grad_fb = lambda x_arr : np.array(gf_b(x_arr), 'float64').reshape(1,len(x_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_str = lambda x_k : np.array2string(x_k.reshape(len(x_k)), precision=3, separator=',')\n",
    "\n",
    "f_str = lambda x : \"{0:.4f}\".format(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputTable:    \n",
    "    def __init__(self):\n",
    "        self.table = pd.DataFrame([],columns=['k', 'x^k', 'f(x^k)', 'd^k', 'a^k', 'x^k+1'])\n",
    "    def add_row(self, k, xk, fxk, dk, ak, xkp):\n",
    "        self.table.loc[len(self.table)] = [k, np_str(xk), f_str(fxk.item()), np_str(dk), ak, np_str(xkp)]\n",
    "    def print_latex(self):\n",
    "        print(self.table.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B : Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoidalFunc = lambda output_array : 1 / (1 + np.exp(-output_array))\n",
    "sigmoidalDeriv = lambda hiddenlayer : hiddenlayer * (1 - hiddenlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(patterns, hiddenLayerSize, alpha = 0.5, learningRate = 0.9, epsilon = 0.001):\n",
    "    t = 0\n",
    "    P = np.size(patterns, 0)\n",
    "    w_matrix = np.random.rand(hiddenLayerSize, np.size(patterns,1)) # patterns data includes y values, its column size is selected since we will add x0 to input layer\n",
    "    W_matrix = np.random.rand(1, hiddenLayerSize+1) # we will add h0 to hidden layer\n",
    "    while(alpha > epsilon):\n",
    "        np.random.shuffle(patterns)\n",
    "        desiredOutputs = patterns[:,:-1].reshape(-1,1)\n",
    "        inputLayers = np.transpose(np.insert(patterns, 0, -1, axis=1)[:,:-1]) # x0 is added to all patterns and its value is -1, output values are excluded\n",
    "        hiddenLayer = np.zeros((hiddenLayerSize+1, 1)) # hiddenlayersize doesn't include h0 so it's added\n",
    "        hiddenLayer[0,:] = -1 # h0 is equal to -1\n",
    "        actualOutput = np.zeros_like(desiredOutputs)\n",
    "        for p in range(P):\n",
    "            hiddenLayer[1:] = sigmoidalFunc(w_matrix @ inputLayers[:,p].reshape(-1,1))\n",
    "            actualOutput[p] = W_matrix @ hiddenLayer\n",
    "            # since the function is linear, net output is equal to actual output\n",
    "            S_output = (1 * (desiredOutputs[p] - actualOutput[p])).reshape(-1,1)\n",
    "            S_hidden = (sigmoidalDeriv(hiddenLayer[1:]) * (np.transpose(W_matrix[:,1:]) @ S_output)).reshape(-1,1)\n",
    "            delta_W = alpha * S_output @ np.transpose(hiddenLayer)\n",
    "            W_matrix += delta_W\n",
    "            delta_w = alpha * S_hidden @ np.transpose(inputLayers[:,p].reshape(-1,1))\n",
    "            w_matrix += delta_w\n",
    "        alpha = learningRate * alpha\n",
    "        t += 1\n",
    "        actualHiddens = w_matrix @ inputLayers # h1, ..., hj\n",
    "        actualOutputMatrix = W_matrix @ np.insert(actualHiddens, 0, -1, axis=0) # o1, ..., oi\n",
    "        error = np.sum(np.square(desiredOutputs - actualOutputMatrix))\n",
    "        print(\"Iteration {0} : error = {1}\".format(t,error))\n",
    "    actualHiddens = w_matrix @ inputLayers # h1, ..., hj\n",
    "    actualOutputMatrix = W_matrix @ np.insert(actualHiddens, 0, -1, axis=0) # o1, ..., oi\n",
    "    error = np.sum(np.square(desiredOutputs - actualOutputMatrix))\n",
    "    return w_matrix, W_matrix, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Iteration 1 : error = 1.3560985520073212e+16\nIteration 2 : error = 6341638102981.615\nIteration 3 : error = 158939293125500.06\nIteration 4 : error = 4190674158747.2886\nIteration 5 : error = 265637470951350.0\nIteration 6 : error = 3931663049387.9385\nIteration 7 : error = 94533724902792.62\nIteration 8 : error = 437660714567587.75\nIteration 9 : error = 413865606076296.6\nIteration 10 : error = 39359456449019.67\nIteration 11 : error = 18882484166805.047\nIteration 12 : error = 25990695426746.055\nIteration 13 : error = 25708786306437.594\nIteration 14 : error = 13675090364300.066\nIteration 15 : error = 159332923059270.2\nIteration 16 : error = 40951095469277.89\nIteration 17 : error = 23446353322013.61\nIteration 18 : error = 97536758521753.03\nIteration 19 : error = 118786373932563.03\nIteration 20 : error = 17280065486303.55\nIteration 21 : error = 12314520607918.656\nIteration 22 : error = 51398546472395.234\nIteration 23 : error = 123971246947390.88\nIteration 24 : error = 58902870683136.92\nIteration 25 : error = 30498053660601.914\nIteration 26 : error = 70972121433298.69\nIteration 27 : error = 48264232624099.1\nIteration 28 : error = 26737238636587.926\nIteration 29 : error = 20002480503068.527\nIteration 30 : error = 30497165599484.016\nIteration 31 : error = 60635120447079.61\nIteration 32 : error = 59121100586240.56\nIteration 33 : error = 55995743301751.06\nIteration 34 : error = 48725623208127.63\nIteration 35 : error = 29718048743190.094\nIteration 36 : error = 56953237410864.17\nIteration 37 : error = 57195391970750.93\nIteration 38 : error = 43961044436155.61\nIteration 39 : error = 46634050848291.86\nIteration 40 : error = 44820141025896.375\nIteration 41 : error = 74049642235787.17\nIteration 42 : error = 57103463598881.22\nIteration 43 : error = 64210829149778.45\nIteration 44 : error = 53638620767067.11\nIteration 45 : error = 44727735940946.23\nIteration 46 : error = 52158663107378.91\nIteration 47 : error = 51354456497510.83\nIteration 48 : error = 53012544339564.73\nIteration 49 : error = 51848437509088.2\nIteration 50 : error = 52901995852859.91\nIteration 51 : error = 56189280443405.55\nIteration 52 : error = 54397251075395.16\nIteration 53 : error = 54681810534852.984\nIteration 54 : error = 55390507926259.7\nIteration 55 : error = 55638158372016.09\nIteration 56 : error = 54626276817974.14\nIteration 57 : error = 54330763614641.8\nIteration 58 : error = 54325713830535.69\nIteration 59 : error = 54836373765539.31\n"
    },
    {
     "data": {
      "text/plain": "(array([[0.26019469, 0.38254563],\n        [0.14178385, 0.84176895],\n        [0.92196021, 0.51127934]]),\n array([[-92.50422294,  93.09305246,  92.97657676,  92.7308395 ]]),\n 54836373765539.31)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns = np.array(train_data)\n",
    "backpropagation(patterns, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.38821993e+11, -5.90337080e+13, -2.35398118e+16],\n",
       "        [ 2.38821648e+11, -5.90341186e+13, -2.35401062e+16],\n",
       "        [ 2.38821796e+11, -5.90339426e+13, -2.35399800e+16]]),\n",
       " array([[-111324.93304916,   99123.48907882,   99138.75872513,\n",
       "           99132.2131042 ]]),\n",
       " 1.2332644345039047e+59)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns2 = np.insert(np.array(train_data), 1, np.square(train_data['x']), axis=1)\n",
    "backpropagation(patterns2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageError(w_matrix, W_matrix, test_data):\n",
    "    inputLayers = np.transpose(np.insert(test_data, 0, -1, axis=1)[:,:-1]) # h1, ..., hj\n",
    "    desiredOutputs = test_data[:,:-1].reshape(-1,1)\n",
    "    actualHiddens = w_matrix @ inputLayers \n",
    "    actualOutputMatrix = W_matrix @ np.insert(actualHiddens, 0, -1, axis=0) # o1, ..., oi\n",
    "    squareResiduals = np.square(desiredOutputs - actualOutputMatrix)\n",
    "    sse = np.sum(squareResiduals)\n",
    "    mse = sse / np.size(desiredOutputs)\n",
    "    variance = np.sum(np.square(mse-squareResiduals)) / (np.size(desiredOutputs) - 1)\n",
    "    return mse, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hiddenUnit(train_data, test_data, Jq = 3, epsilon = 0.001):\n",
    "    train = np.array(train_data)\n",
    "    test = np.array(test_data)\n",
    "    q = 1\n",
    "    Et = np.infty\n",
    "    while(True):\n",
    "        patterns = np.copy(train)\n",
    "        w, W, total_error = backpropagation(patterns, Jq, epsilon=epsilon)\n",
    "        Etp, var = averageError(w, W, test)\n",
    "        print(\"{0} hidden units : MSE = {1}\".format(Jq,Etp))\n",
    "        if(Etp >= Et):\n",
    "            break\n",
    "        Jq += 1\n",
    "        q += 1\n",
    "        Et = Etp\n",
    "    return Jq-1, Et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/akin/bin/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: overflow encountered in exp\n  \"\"\"Entry point for launching an IPython kernel.\nIteration 1 : error = 2033226643273957.2\nIteration 2 : error = 3230668282252178.0\nIteration 3 : error = 1994390938542850.8\nIteration 4 : error = 2152785718311086.8\nIteration 5 : error = 3005865593498625.5\nIteration 6 : error = 2288708863593874.0\nIteration 7 : error = 2373841813838735.5\nIteration 8 : error = 2967739917438883.0\nIteration 9 : error = 3494459705305237.0\nIteration 10 : error = 2171283631237008.0\nIteration 11 : error = 2821511755266679.0\nIteration 12 : error = 2274317204692394.0\nIteration 13 : error = 2370863666923321.0\nIteration 14 : error = 2557801062312494.5\nIteration 15 : error = 2194870358275789.5\nIteration 16 : error = 2633312919586308.0\nIteration 17 : error = 2547455126184101.0\nIteration 18 : error = 2687990440456719.0\nIteration 19 : error = 2403316904342257.0\nIteration 20 : error = 2552636850228919.5\nIteration 21 : error = 2600017808166717.5\nIteration 22 : error = 2611254479692464.0\nIteration 23 : error = 2721734394538605.0\nIteration 24 : error = 2453531623866253.0\nIteration 25 : error = 2363029745178523.5\nIteration 26 : error = 2517787763921906.5\nIteration 27 : error = 2852456612910409.0\nIteration 28 : error = 2577335182155755.5\nIteration 29 : error = 2640092817386139.5\nIteration 30 : error = 2636471563935471.0\nIteration 31 : error = 2575663143009643.5\nIteration 32 : error = 2444952602350352.5\nIteration 33 : error = 2514200859649880.0\nIteration 34 : error = 2461748733223265.0\nIteration 35 : error = 2630843079569613.0\nIteration 36 : error = 2602644687878367.5\nIteration 37 : error = 2609687966893756.0\nIteration 38 : error = 2527324997128351.0\nIteration 39 : error = 2538904600771300.0\nIteration 40 : error = 2513716795415892.0\nIteration 41 : error = 2596561782255405.0\nIteration 42 : error = 2571964697226685.0\nIteration 43 : error = 2526826148207622.0\nIteration 44 : error = 2559510090886184.0\nIteration 45 : error = 2524776640259550.5\nIteration 46 : error = 2540139061115648.0\nIteration 47 : error = 2505063907435263.0\nIteration 48 : error = 2522307949191689.5\nIteration 49 : error = 2511165118659522.5\nIteration 50 : error = 2512517932999600.5\nIteration 51 : error = 2528561285322310.0\nIteration 52 : error = 2533808306995309.0\nIteration 53 : error = 2540828013058082.0\nIteration 54 : error = 2536188567880648.0\nIteration 55 : error = 2535105928066569.5\nIteration 56 : error = 2530424558584096.5\nIteration 57 : error = 2530761092097500.0\nIteration 58 : error = 2531226259492960.5\nIteration 59 : error = 2532259136646125.0\n3 hidden units : MSE = 4228165628942.7915\nIteration 1 : error = 4.98008030608129e+50\nIteration 2 : error = 4.98008030608129e+50\nIteration 3 : error = 4.980080306081291e+50\nIteration 4 : error = 4.980080306081291e+50\nIteration 5 : error = 4.980080306081291e+50\nIteration 6 : error = 4.98008030608129e+50\nIteration 7 : error = 4.980080306081291e+50\nIteration 8 : error = 4.98008030608129e+50\nIteration 9 : error = 4.980080306081291e+50\nIteration 10 : error = 4.980080306081291e+50\nIteration 11 : error = 4.980080306081291e+50\nIteration 12 : error = 4.9800803060812916e+50\nIteration 13 : error = 4.980080306081291e+50\nIteration 14 : error = 4.980080306081291e+50\nIteration 15 : error = 4.980080306081291e+50\nIteration 16 : error = 4.980080306081291e+50\nIteration 17 : error = 4.98008030608129e+50\nIteration 18 : error = 4.980080306081291e+50\nIteration 19 : error = 4.980080306081291e+50\nIteration 20 : error = 4.98008030608129e+50\nIteration 21 : error = 4.98008030608129e+50\nIteration 22 : error = 4.98008030608129e+50\nIteration 23 : error = 4.98008030608129e+50\nIteration 24 : error = 4.980080306081291e+50\nIteration 25 : error = 4.980080306081291e+50\nIteration 26 : error = 4.98008030608129e+50\nIteration 27 : error = 4.98008030608129e+50\nIteration 28 : error = 4.98008030608129e+50\nIteration 29 : error = 4.98008030608129e+50\nIteration 30 : error = 4.980080306081291e+50\nIteration 31 : error = 4.98008030608129e+50\nIteration 32 : error = 4.98008030608129e+50\nIteration 33 : error = 4.980080306081291e+50\nIteration 34 : error = 4.98008030608129e+50\nIteration 35 : error = 4.9800803060812916e+50\nIteration 36 : error = 4.980080306081291e+50\nIteration 37 : error = 4.980080306081291e+50\nIteration 38 : error = 4.98008030608129e+50\nIteration 39 : error = 4.980080306081291e+50\nIteration 40 : error = 4.98008030608129e+50\nIteration 41 : error = 4.980080306081291e+50\nIteration 42 : error = 4.980080306081291e+50\nIteration 43 : error = 4.980080306081291e+50\nIteration 44 : error = 4.98008030608129e+50\nIteration 45 : error = 4.980080306081291e+50\nIteration 46 : error = 4.980080306081291e+50\nIteration 47 : error = 4.980080306081291e+50\nIteration 48 : error = 4.980080306081291e+50\nIteration 49 : error = 4.980080306081291e+50\nIteration 50 : error = 4.98008030608129e+50\nIteration 51 : error = 4.980080306081291e+50\nIteration 52 : error = 4.980080306081291e+50\nIteration 53 : error = 4.980080306081291e+50\nIteration 54 : error = 4.98008030608129e+50\nIteration 55 : error = 4.98008030608129e+50\nIteration 56 : error = 4.98008030608129e+50\nIteration 57 : error = 4.98008030608129e+50\nIteration 58 : error = 4.98008030608129e+50\nIteration 59 : error = 4.980080306081291e+50\n4 hidden units : MSE = 8.315458521032069e+47\n"
    },
    {
     "data": {
      "text/plain": "(3, 4228165628942.7915)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddenUnit(train_data, test_data, epsilon=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}