{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sympy import Symbol, lambdify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Input/training.dat', sep=' ', header=None, names=['x', 'y']);\n",
    "test_data = pd.read_csv('Input/test.dat', sep=' ', header=None, names=['x', 'y']);\n",
    "\n",
    "x_train = np.array(train_data['x'])\n",
    "y_train = np.array(train_data['y'])\n",
    "\n",
    "w0 = Symbol(\"w0\")\n",
    "w1 = Symbol(\"w1\")\n",
    "w2 = Symbol(\"w2\")\n",
    "\n",
    "func_a = np.sum(np.square(y_train - w0 - w1 * x_train))\n",
    "f_a = lambdify([[w0, w1]], func_a, \"numpy\")\n",
    "gf_a = lambdify([[w0, w1]], func_a.diff([[w0, w1]]), \"numpy\")\n",
    "grad_fa = lambda x_arr : np.array(gf_a(x_arr), 'float64').reshape(1,len(x_arr))\n",
    "\n",
    "func_b = np.sum(np.square(y_train - w0 - w1 * x_train - w2 * x_train**2))\n",
    "f_b = lambdify([[w0, w1, w2]], func_b, \"numpy\")\n",
    "gf_b = lambdify([[w0, w1, w2]], func_b.diff([[w0, w1, w2]]), \"numpy\")\n",
    "grad_fb = lambda x_arr : np.array(gf_b(x_arr), 'float64').reshape(1,len(x_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_str = lambda x_k : np.array2string(x_k.reshape(len(x_k)), precision=3, separator=',')\n",
    "\n",
    "f_str = lambda x : \"{0:.4f}\".format(x)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputTable:    \n",
    "    def __init__(self):\n",
    "        self.table = pd.DataFrame([],columns=['k', 'x^k', 'f(x^k)', 'd^k', 'a^k', 'x^k+1'])\n",
    "    def add_row(self, k, xk, fxk, dk, ak, xkp):\n",
    "        self.table.loc[len(self.table)] = [k, np_str(xk), f_str(fxk.item()), np_str(dk), ak, np_str(xkp)]\n",
    "    def print_latex(self):\n",
    "        print(self.table.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part B : Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(patterns, hiddenLayerSize, alpha = 0.5, learningRate = 0.9, epsilon = 0.001):\n",
    "    t = 0\n",
    "    w_matrix = np.random.rand((hiddenLayerSize, np.size(patterns,1))) # patterns data includes y values, its column size is selected since we will add x0 to input layer\n",
    "    W_matrix = np.random.rand((1, hiddenLayerSize+1)) # we will add h0 to hidden layer\n",
    "    while(alpha > epsilon):\n",
    "        np.random.shuffle(patterns)\n",
    "        expectedOutputs = patterns[:,:-1]\n",
    "        inputLayers = np.insert(patterns, 0, -1, axis=1)[:,:-1] # x0 is added to all patterns and its value is -1, output values are excluded\n",
    "        hiddenLayer = np.zeros((hiddenLayerSize+1, 1)) # hiddenlayersize doesn't include h0 so it's added\n",
    "        hiddenLayer[0,0] = -1 # h0 is equal to -1\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}