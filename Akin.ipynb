{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sympy import Symbol, lambdify\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Input/training.dat', sep=' ', header=None, names=['x', 'y']);\n",
    "test_data = pd.read_csv('Input/test.dat', sep=' ', header=None, names=['x', 'y']);\n",
    "\n",
    "x_train = np.array(train_data['x'])\n",
    "y_train = np.array(train_data['y'])\n",
    "\n",
    "w0 = Symbol(\"w0\")\n",
    "w1 = Symbol(\"w1\")\n",
    "w2 = Symbol(\"w2\")\n",
    "\n",
    "func_a = np.sum(np.square(y_train - w0 - w1 * x_train))\n",
    "f_a = lambdify([[w0, w1]], func_a, \"numpy\")\n",
    "gf_a = lambdify([[w0, w1]], func_a.diff([[w0, w1]]), \"numpy\")\n",
    "grad_fa = lambda x_arr : np.array(gf_a(x_arr), 'float64').reshape(1,len(x_arr))\n",
    "\n",
    "func_b = np.sum(np.square(y_train - w0 - w1 * x_train - w2 * x_train**2))\n",
    "f_b = lambdify([[w0, w1, w2]], func_b, \"numpy\")\n",
    "gf_b = lambdify([[w0, w1, w2]], func_b.diff([[w0, w1, w2]]), \"numpy\")\n",
    "grad_fb = lambda x_arr : np.array(gf_b(x_arr), 'float64').reshape(1,len(x_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRegressionGraph(data, regFunc, labels=[], name=\"graph\"):\n",
    "    xmin = data[:,0].min\n",
    "    xmax = data[:,0].max\n",
    "    t1 = np.arange(xmin-1, xmax+1, 0.1)\n",
    "    plt.figure()\n",
    "    plt.plot(t1, regFunc(t1), 'b-', label='Regression line')\n",
    "    plt.scatter(data[:,0], data[:,1], color=\"black\", label=\"Data points\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"{0}.png\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_str = lambda x_k : np.array2string(x_k.reshape(len(x_k)), precision=3, separator=',')\n",
    "\n",
    "f_str = lambda x : \"{0:.4f}\".format(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputTable:    \n",
    "    def __init__(self):\n",
    "        self.table = pd.DataFrame([],columns=['k', 'x^k', 'f(x^k)', 'd^k', 'a^k', 'x^k+1'])\n",
    "    def add_row(self, k, xk, fxk, dk, ak, xkp):\n",
    "        self.table.loc[len(self.table)] = [k, np_str(xk), f_str(fxk.item()), np_str(dk), ak, np_str(xkp)]\n",
    "    def print_latex(self):\n",
    "        print(self.table.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B : Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoidalFunc = lambda output_array : 1 / (1 + np.exp(-output_array))\n",
    "sigmoidalDeriv = lambda hiddenlayer : hiddenlayer * (1 - hiddenlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(trainingData, hiddenLayerSize, alpha = 0.5, momentum = 0.9, epsilon = 0.001, seed = 440):\n",
    "    np.random.seed(seed)\n",
    "    t = 0\n",
    "    patterns = np.copy(trainingData)\n",
    "    patterns = np.insert(patterns, 0, -1, axis=1) # x0 = -1 unit is added\n",
    "    P = np.size(patterns, 0) # pattern size\n",
    "    I = 1 # output unit size\n",
    "    K = np.size(patterns, 1) - I # input layer size\n",
    "    J = hiddenLayerSize + 1 # h0 = -1 is added\n",
    "    w_matrix = np.random.rand(J, K) # weights between input and hidden layer (we will exclude first row in the result since h0 is excluded)\n",
    "    W_matrix = np.random.rand(I, J) # weight between hidden and output layer\n",
    "    while(alpha >= epsilon):\n",
    "        np.random.shuffle(patterns)\n",
    "        x = np.transpose(patterns[:,:-1]).reshape(K, -1)\n",
    "        y = patterns[:,-1]\n",
    "        H = np.zeros(J)\n",
    "        H[0] = -1 # h0 is equal to -1\n",
    "        O = np.zeros_like(y)\n",
    "        for p in range(P):\n",
    "            for j in range(1,J):\n",
    "                hj = np.sum(w_matrix[j] * x[:,p])\n",
    "                H[j] = sigmoidalFunc(hj)\n",
    "            for i in range(I):\n",
    "                o = np.sum(W_matrix[i] * H)\n",
    "                O[p] = o # linear function g(x) = x\n",
    "            S_O = 0 # since there is only one output unit\n",
    "            S_H = np.zeros_like(H)\n",
    "            for i in range(I):\n",
    "                S_O = 1 * (y[p] - O[p])\n",
    "            for j in range(1,J):\n",
    "                S_H[j] = sigmoidalDeriv(H[j]) * np.sum(W_matrix[0,j] * S_O)\n",
    "            for j in range(J):\n",
    "                dWj = alpha * S_O * H[j]\n",
    "                W_matrix[0,j] += dWj\n",
    "            for k in range(K):\n",
    "                dwk = alpha * S_H * x[k,p]\n",
    "                w_matrix[:,k] += dwk\n",
    "        alpha *= momentum\n",
    "        t += 1\n",
    "        actualHiddens = sigmoidalFunc(w_matrix @ x)\n",
    "        actualHiddens[0,:] = -1 # h1, ..., hj\n",
    "        actualOutputMatrix = W_matrix @ actualHiddens # o1, ..., oi\n",
    "        error = np.sum(np.square(y - actualOutputMatrix))\n",
    "        print(\"Iteration {0} : error = {1}\".format(t,error))\n",
    "    return w_matrix, W_matrix, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagationWithMatrix(patterns, hiddenLayerSize, alpha = 0.5, momentum = 0.9, epsilon = 0.001, seed = 440):\n",
    "    np.random.seed(seed)\n",
    "    t = 0\n",
    "    P = np.size(patterns, 0)\n",
    "    w_matrix = np.random.rand(hiddenLayerSize, np.size(patterns,1))*1 # patterns data includes y values, its column size is selected since we will add x0 to input layer\n",
    "    W_matrix = np.random.rand(1, hiddenLayerSize+1)*1 # we will add h0 to hidden layer\n",
    "    while(alpha > epsilon):\n",
    "        np.random.shuffle(patterns)\n",
    "        desiredOutputs = patterns[:,-1].reshape(-1,1)\n",
    "        inputLayers = np.transpose(np.insert(patterns, 0, -1, axis=1)[:,:-1]) # x0 is added to all patterns and its value is -1, output values are excluded\n",
    "        hiddenLayer = np.zeros((hiddenLayerSize+1, 1)) # hiddenlayersize doesn't include h0 so it's added\n",
    "        hiddenLayer[0,:] = -1 # h0 is equal to -1\n",
    "        actualOutput = np.zeros_like(desiredOutputs)\n",
    "        for p in range(P):\n",
    "            hiddenLayer[1:] = sigmoidalFunc(w_matrix @ inputLayers[:,p].reshape(-1,1))\n",
    "            actualOutput[p] = W_matrix @ hiddenLayer\n",
    "            # since the function is linear, net output is equal to actual output\n",
    "            S_output = (1 * (desiredOutputs[p] - actualOutput[p])).reshape(-1,1)\n",
    "            S_hidden = (sigmoidalDeriv(hiddenLayer[1:]) * (np.transpose(W_matrix[:,1:]) @ S_output)).reshape(-1,1)\n",
    "            delta_W = alpha * S_output @ np.transpose(hiddenLayer)\n",
    "            W_matrix += delta_W\n",
    "            delta_w = alpha * S_hidden @ np.transpose(inputLayers[:,p].reshape(-1,1))\n",
    "            w_matrix += delta_w\n",
    "        alpha = momentum * alpha\n",
    "        t += 1\n",
    "        actualHiddens = sigmoidalFunc(w_matrix @ inputLayers) # h1, ..., hj\n",
    "        actualOutputMatrix = W_matrix @ np.insert(actualHiddens, 0, -1, axis=0) # o1, ..., oi\n",
    "        error = np.sum(np.square(desiredOutputs - np.transpose(actualOutputMatrix)))\n",
    "        print(\"Iteration {0} : error = {1}\".format(t,error))\n",
    "    return w_matrix, W_matrix, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/akin/bin/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: overflow encountered in exp\n  \"\"\"Entry point for launching an IPython kernel.\nIteration 1 : error = 65990060.54243174\nIteration 2 : error = 10113825.583399063\nIteration 3 : error = 43808090.295681074\nIteration 4 : error = 12505564.676437719\nIteration 5 : error = 8089966.405235191\nIteration 6 : error = 11833632.05725339\nIteration 7 : error = 12836098.518659439\nIteration 8 : error = 11965313.508335438\nIteration 9 : error = 8680024.68645668\nIteration 10 : error = 8135515.189156784\nIteration 11 : error = 8618921.519123074\nIteration 12 : error = 8443978.62606255\nIteration 13 : error = 8326509.097579323\nIteration 14 : error = 8121047.848801743\nIteration 15 : error = 8163216.338089563\nIteration 16 : error = 8545592.633515783\nIteration 17 : error = 8656896.371558119\nIteration 18 : error = 8793583.228306344\nIteration 19 : error = 9995984.578043804\nIteration 20 : error = 7987030.096374455\nIteration 21 : error = 7956666.186538142\nIteration 22 : error = 10745125.030414928\nIteration 23 : error = 8825952.889630657\nIteration 24 : error = 7955387.318215961\nIteration 25 : error = 8063513.367453453\nIteration 26 : error = 8601016.056709459\nIteration 27 : error = 8365075.045011002\nIteration 28 : error = 9739542.711423445\nIteration 29 : error = 8626635.881034818\nIteration 30 : error = 7972491.015456207\nIteration 31 : error = 8084599.7106194375\nIteration 32 : error = 8090181.569586102\nIteration 33 : error = 8009161.303768506\nIteration 34 : error = 8307717.736687439\nIteration 35 : error = 8029553.26537001\nIteration 36 : error = 7977191.999746014\nIteration 37 : error = 7958138.6004361\nIteration 38 : error = 7981397.209705493\nIteration 39 : error = 7953804.639178817\nIteration 40 : error = 8158270.147813448\nIteration 41 : error = 7954032.697591651\nIteration 42 : error = 7970275.624704275\nIteration 43 : error = 7989714.567670081\nIteration 44 : error = 7968294.782614133\nIteration 45 : error = 7966806.924724458\nIteration 46 : error = 7960393.070642905\nIteration 47 : error = 7957935.357290845\nIteration 48 : error = 7953580.688994635\nIteration 49 : error = 7953805.785581182\nIteration 50 : error = 7954776.2682595\nIteration 51 : error = 7954463.639742318\nIteration 52 : error = 7953597.646980109\nIteration 53 : error = 7953552.365394771\nIteration 54 : error = 7953539.373690909\nIteration 55 : error = 7953800.709844423\nIteration 56 : error = 7953891.693413229\nIteration 57 : error = 7954283.363155966\nIteration 58 : error = 7954193.4698333815\nIteration 59 : error = 7954415.602024415\n"
    },
    {
     "data": {
      "text/plain": "(array([[ 1.71858636e-01,  9.65145829e-01],\n        [ 8.47339514e-01,  3.97995080e-01],\n        [ 6.16147498e-01,  6.29039082e-01],\n        [ 3.13448399e+02, -3.69468170e+04]]),\n array([[-127.77235014,  128.42128315,  128.78880676,  249.38554076]]),\n 7954415.602024415)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns = np.array(train_data)\n",
    "backpropagation(patterns, 3, seed=440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/akin/bin/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: overflow encountered in exp\n  \"\"\"Entry point for launching an IPython kernel.\nIteration 1 : error = 8816929.259708159\nIteration 2 : error = 35416253.22628992\nIteration 3 : error = 8229024.724786728\nIteration 4 : error = 13164051.38481994\nIteration 5 : error = 15566757.510988269\nIteration 6 : error = 23564751.692394815\nIteration 7 : error = 53413296.88368054\nIteration 8 : error = 8874842.832893368\nIteration 9 : error = 16104438.438315174\nIteration 10 : error = 19138031.8672025\nIteration 11 : error = 8787954.196188327\nIteration 12 : error = 9487006.006960494\nIteration 13 : error = 8848522.9449617\nIteration 14 : error = 8041621.976536453\nIteration 15 : error = 8811230.183558227\nIteration 16 : error = 7983583.827350191\nIteration 17 : error = 8200299.000644428\nIteration 18 : error = 8601616.187121753\nIteration 19 : error = 9006039.439315354\nIteration 20 : error = 8088580.127783587\nIteration 21 : error = 8830037.52002777\nIteration 22 : error = 9067076.772440638\nIteration 23 : error = 8332115.190639583\nIteration 24 : error = 7953551.613080238\nIteration 25 : error = 8135425.774272785\nIteration 26 : error = 8020732.190837531\nIteration 27 : error = 8098359.552492526\nIteration 28 : error = 8003471.914861883\nIteration 29 : error = 7964538.080020943\nIteration 30 : error = 8017402.172059927\nIteration 31 : error = 8114208.977791673\nIteration 32 : error = 8057912.8363245055\nIteration 33 : error = 8006982.595615344\nIteration 34 : error = 7953699.985097693\nIteration 35 : error = 7953622.430792454\nIteration 36 : error = 7967588.135126663\nIteration 37 : error = 8031052.611641172\nIteration 38 : error = 7998728.2759004915\nIteration 39 : error = 7987646.749575665\nIteration 40 : error = 8021721.206016026\nIteration 41 : error = 7983345.612163168\nIteration 42 : error = 7991508.821021123\nIteration 43 : error = 7958543.5875437725\nIteration 44 : error = 7957833.414874554\nIteration 45 : error = 7953550.789499461\nIteration 46 : error = 7966646.686935366\nIteration 47 : error = 7954034.677815243\nIteration 48 : error = 7953757.23565327\nIteration 49 : error = 7954619.291296683\nIteration 50 : error = 7956950.19058742\nIteration 51 : error = 7954753.102880033\nIteration 52 : error = 7954967.705624387\nIteration 53 : error = 7954106.67874203\nIteration 54 : error = 7953854.318470058\nIteration 55 : error = 7953599.827251416\nIteration 56 : error = 7953865.975258309\nIteration 57 : error = 7953552.280365617\nIteration 58 : error = 7953737.631524678\nIteration 59 : error = 7953714.347670076\n"
    },
    {
     "data": {
      "text/plain": "(array([[  0.62495165, -21.52694768],\n        [  0.25547392,   0.39632991],\n        [  0.3773151 ,   0.99657423]]),\n array([[-128.24385088, 1238.84623456,  129.41258477,  128.96205743]]),\n 7953714.347670076)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns = np.array(train_data)\n",
    "backpropagationWithMatrix(patterns, 3, seed=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Iteration 1 : error = 88280657.92971183\nIteration 2 : error = 78291309.58459358\nIteration 3 : error = 21538937.469661705\nIteration 4 : error = 63672657.85242866\nIteration 5 : error = 7953698.8945387\nIteration 6 : error = 21926469.828171175\nIteration 7 : error = 12495620.773744613\nIteration 8 : error = 33722797.814106144\nIteration 9 : error = 8119178.015434197\nIteration 10 : error = 14318492.390151966\nIteration 11 : error = 20106416.49474501\nIteration 12 : error = 10238905.356222112\nIteration 13 : error = 34003572.146542765\nIteration 14 : error = 7989858.2323091\nIteration 15 : error = 9526449.375450313\nIteration 16 : error = 11577355.230264327\nIteration 17 : error = 7953653.602025525\nIteration 18 : error = 8341029.254973405\nIteration 19 : error = 8049490.186094718\nIteration 20 : error = 8051395.941854635\nIteration 21 : error = 10968614.132510625\nIteration 22 : error = 8409331.516944073\nIteration 23 : error = 8626602.000976456\nIteration 24 : error = 8528248.111838715\nIteration 25 : error = 9381197.306298038\nIteration 26 : error = 8432617.342559423\nIteration 27 : error = 8515819.586510273\nIteration 28 : error = 8903934.1246458\nIteration 29 : error = 8192920.474597662\nIteration 30 : error = 8373214.770115601\nIteration 31 : error = 8377701.182217754\nIteration 32 : error = 8360715.59780536\nIteration 33 : error = 8279140.4021526165\nIteration 34 : error = 8032865.415148194\nIteration 35 : error = 7986259.339168833\nIteration 36 : error = 7969094.399699611\nIteration 37 : error = 7953683.010295117\nIteration 38 : error = 8122525.045601774\nIteration 39 : error = 8327341.274967308\nIteration 40 : error = 7997198.848366971\nIteration 41 : error = 8028738.3695118865\nIteration 42 : error = 7956905.5426598005\nIteration 43 : error = 7982241.838577611\nIteration 44 : error = 7953572.455320623\nIteration 45 : error = 7960144.307342453\nIteration 46 : error = 7968980.623936103\nIteration 47 : error = 7954796.470132911\nIteration 48 : error = 7953879.313373294\nIteration 49 : error = 7958864.496099917\nIteration 50 : error = 7953755.116776071\nIteration 51 : error = 7954041.394876102\nIteration 52 : error = 7953538.885751509\nIteration 53 : error = 7953651.846792777\nIteration 54 : error = 7953690.521983004\nIteration 55 : error = 7954010.23981591\nIteration 56 : error = 7953543.977925938\nIteration 57 : error = 7953951.451978632\nIteration 58 : error = 7954178.586822565\nIteration 59 : error = 7954322.33853856\n"
    },
    {
     "data": {
      "text/plain": "(array([[0.17185864, 0.96514583, 0.84733951],\n        [0.39799508, 0.6161475 , 0.62903908],\n        [0.15285732, 0.17501496, 0.38176556],\n        [0.26716745, 0.63469106, 0.28434213]]),\n array([[-96.51737743,  98.39875203,  98.06407988,  97.76263623]]),\n 7954322.33853856)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns2 = np.insert(np.array(train_data), 1, np.square(train_data['x']), axis=1)\n",
    "backpropagation(patterns2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageError(w_matrix, W_matrix, test_data):\n",
    "    inputLayers = np.transpose(np.insert(test_data, 0, -1, axis=1)[:,:-1]) # h1, ..., hj\n",
    "    desiredOutputs = test_data[:,-1].reshape(-1,1)\n",
    "    actualHiddens = sigmoidalFunc(w_matrix @ inputLayers)\n",
    "    actualOutputMatrix = W_matrix @ np.insert(actualHiddens, 0, -1, axis=0) # o1, ..., oi\n",
    "    squareResiduals = np.square(desiredOutputs - np.transpose(actualOutputMatrix))\n",
    "    sse = np.sum(squareResiduals)\n",
    "    mse = sse / np.size(desiredOutputs)\n",
    "    variance = np.sum(np.square(mse-squareResiduals)) / (np.size(desiredOutputs) - 1)\n",
    "    return mse, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hiddenUnit(train_data, test_data, Jq = 3, epsilon = 0.001, seed = 440):\n",
    "    train = np.array(train_data)\n",
    "    test = np.array(test_data)\n",
    "    q = 1\n",
    "    Et = np.infty\n",
    "    while(True):\n",
    "        patterns = np.copy(train)\n",
    "        w, W, total_error = backpropagation(patterns, Jq, epsilon=epsilon, seed = seed)\n",
    "        Etp, var = averageError(w, W, test)\n",
    "        print(\"{0} hidden units : MSE = {1} , variance = {2}\".format(Jq,Etp,var))\n",
    "        if(Etp >= Et):\n",
    "            break\n",
    "        Jq += 1\n",
    "        q += 1\n",
    "        Et = Etp\n",
    "    return Jq-1, Et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/akin/bin/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: overflow encountered in exp\n  \"\"\"Entry point for launching an IPython kernel.\nIteration 1 : error = 65990060.54243174\nIteration 2 : error = 10113825.583399063\nIteration 3 : error = 43808090.295681074\nIteration 4 : error = 12505564.676437719\nIteration 5 : error = 8089966.405235191\nIteration 6 : error = 11833632.05725339\nIteration 7 : error = 12836098.518659439\nIteration 8 : error = 11965313.508335438\nIteration 9 : error = 8680024.68645668\nIteration 10 : error = 8135515.189156784\nIteration 11 : error = 8618921.519123074\nIteration 12 : error = 8443978.62606255\nIteration 13 : error = 8326509.097579323\nIteration 14 : error = 8121047.848801743\nIteration 15 : error = 8163216.338089563\nIteration 16 : error = 8545592.633515783\nIteration 17 : error = 8656896.371558119\nIteration 18 : error = 8793583.228306344\nIteration 19 : error = 9995984.578043804\nIteration 20 : error = 7987030.096374455\nIteration 21 : error = 7956666.186538142\nIteration 22 : error = 10745125.030414928\nIteration 23 : error = 8825952.889630657\nIteration 24 : error = 7955387.318215961\nIteration 25 : error = 8063513.367453453\nIteration 26 : error = 8601016.056709459\nIteration 27 : error = 8365075.045011002\nIteration 28 : error = 9739542.711423445\nIteration 29 : error = 8626635.881034818\nIteration 30 : error = 7972491.015456207\nIteration 31 : error = 8084599.7106194375\nIteration 32 : error = 8090181.569586102\nIteration 33 : error = 8009161.303768506\nIteration 34 : error = 8307717.736687439\nIteration 35 : error = 8029553.26537001\nIteration 36 : error = 7977191.999746014\nIteration 37 : error = 7958138.6004361\nIteration 38 : error = 7981397.209705493\nIteration 39 : error = 7953804.639178817\nIteration 40 : error = 8158270.147813448\nIteration 41 : error = 7954032.697591651\nIteration 42 : error = 7970275.624704275\nIteration 43 : error = 7989714.567670081\nIteration 44 : error = 7968294.782614133\nIteration 45 : error = 7966806.924724458\nIteration 46 : error = 7960393.070642905\nIteration 47 : error = 7957935.357290845\nIteration 48 : error = 7953580.688994635\nIteration 49 : error = 7953805.785581182\nIteration 50 : error = 7954776.2682595\nIteration 51 : error = 7954463.639742318\nIteration 52 : error = 7953597.646980109\nIteration 53 : error = 7953552.365394771\nIteration 54 : error = 7953539.373690909\nIteration 55 : error = 7953800.709844423\nIteration 56 : error = 7953891.693413229\nIteration 57 : error = 7954283.363155966\nIteration 58 : error = 7954193.4698333815\nIteration 59 : error = 7954415.602024415\n"
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 5 is different from 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-00131f95f587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhiddenUnit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m440\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-3163fd59843d>\u001b[0m in \u001b[0;36mhiddenUnit\u001b[0;34m(train_data, test_data, Jq, epsilon, seed)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mEtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} hidden units : MSE = {1} , variance = {2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEtp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEtp\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mEt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a121e1d2c604>\u001b[0m in \u001b[0;36maverageError\u001b[0;34m(w_matrix, W_matrix, test_data)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdesiredOutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mactualHiddens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoidalFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_matrix\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0minputLayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mactualOutputMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW_matrix\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactualHiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# o1, ..., oi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msquareResiduals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesiredOutputs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactualOutputMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquareResiduals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 5 is different from 4)"
     ]
    }
   ],
   "source": [
    "hiddenUnit(train_data, test_data, epsilon=0.001, seed = 440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Iteration 1 : error = 88280657.92971183\nIteration 2 : error = 78291309.58459358\nIteration 3 : error = 21538937.469661705\nIteration 4 : error = 63672657.85242866\nIteration 5 : error = 7953698.8945387\nIteration 6 : error = 21926469.828171175\nIteration 7 : error = 12495620.773744613\nIteration 8 : error = 33722797.814106144\nIteration 9 : error = 8119178.015434197\nIteration 10 : error = 14318492.390151966\nIteration 11 : error = 20106416.49474501\nIteration 12 : error = 10238905.356222112\nIteration 13 : error = 34003572.146542765\nIteration 14 : error = 7989858.2323091\nIteration 15 : error = 9526449.375450313\nIteration 16 : error = 11577355.230264327\nIteration 17 : error = 7953653.602025525\nIteration 18 : error = 8341029.254973405\nIteration 19 : error = 8049490.186094718\nIteration 20 : error = 8051395.941854635\nIteration 21 : error = 10968614.132510625\nIteration 22 : error = 8409331.516944073\nIteration 23 : error = 8626602.000976456\nIteration 24 : error = 8528248.111838715\nIteration 25 : error = 9381197.306298038\nIteration 26 : error = 8432617.342559423\nIteration 27 : error = 8515819.586510273\nIteration 28 : error = 8903934.1246458\nIteration 29 : error = 8192920.474597662\nIteration 30 : error = 8373214.770115601\nIteration 31 : error = 8377701.182217754\nIteration 32 : error = 8360715.59780536\nIteration 33 : error = 8279140.4021526165\nIteration 34 : error = 8032865.415148194\nIteration 35 : error = 7986259.339168833\nIteration 36 : error = 7969094.399699611\nIteration 37 : error = 7953683.010295117\nIteration 38 : error = 8122525.045601774\nIteration 39 : error = 8327341.274967308\nIteration 40 : error = 7997198.848366971\nIteration 41 : error = 8028738.3695118865\nIteration 42 : error = 7956905.5426598005\nIteration 43 : error = 7982241.838577611\nIteration 44 : error = 7953572.455320623\nIteration 45 : error = 7960144.307342453\nIteration 46 : error = 7968980.623936103\nIteration 47 : error = 7954796.470132911\nIteration 48 : error = 7953879.313373294\nIteration 49 : error = 7958864.496099917\nIteration 50 : error = 7953755.116776071\nIteration 51 : error = 7954041.394876102\nIteration 52 : error = 7953538.885751509\nIteration 53 : error = 7953651.846792777\nIteration 54 : error = 7953690.521983004\nIteration 55 : error = 7954010.23981591\nIteration 56 : error = 7953543.977925938\nIteration 57 : error = 7953951.451978632\nIteration 58 : error = 7954178.586822565\nIteration 59 : error = 7954322.33853856\n"
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 5 is different from 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e8e282493292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhiddenUnit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-3163fd59843d>\u001b[0m in \u001b[0;36mhiddenUnit\u001b[0;34m(train_data, test_data, Jq, epsilon, seed)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mEtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} hidden units : MSE = {1} , variance = {2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEtp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEtp\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mEt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a121e1d2c604>\u001b[0m in \u001b[0;36maverageError\u001b[0;34m(w_matrix, W_matrix, test_data)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdesiredOutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mactualHiddens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoidalFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_matrix\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0minputLayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mactualOutputMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW_matrix\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactualHiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# o1, ..., oi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msquareResiduals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesiredOutputs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactualOutputMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquareResiduals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 5 is different from 4)"
     ]
    }
   ],
   "source": [
    "train_d = np.insert(np.array(train_data), 1, np.square(train_data['x']), axis=1)\n",
    "test_d = np.insert(np.array(test_data), 1, np.square(test_data['x']), axis=1)\n",
    "hiddenUnit(train_d, test_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}