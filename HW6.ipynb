{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sympy import Symbol, lambdify\n",
    "import pdb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Input/training.dat', sep=' ', header=None, names=['x', 'y']);\n",
    "test_data = pd.read_csv('Input/test.dat', sep=' ', header=None, names=['x', 'y']);\n",
    "\n",
    "x_train = np.array(train_data['x'])\n",
    "y_train = np.array(train_data['y'])\n",
    "\n",
    "w0 = Symbol(\"w0\")\n",
    "w1 = Symbol(\"w1\")\n",
    "w2 = Symbol(\"w2\")\n",
    "\n",
    "func_a = np.sum(np.square(y_train - w0 - w1 * x_train))\n",
    "f_a = lambdify([[w0, w1]], func_a, \"numpy\")\n",
    "gf_a = lambdify([[w0, w1]], func_a.diff([[w0, w1]]), \"numpy\")\n",
    "grad_fa = lambda x_arr : np.array(gf_a(x_arr), 'float64').reshape(1,len(x_arr))\n",
    "\n",
    "func_b = np.sum(np.square(y_train - w0 - w1 * x_train - w2 * x_train**2))\n",
    "f_b = lambdify([[w0, w1, w2]], func_b, \"numpy\")\n",
    "gf_b = lambdify([[w0, w1, w2]], func_b.diff([[w0, w1, w2]]), \"numpy\")\n",
    "grad_fb = lambda x_arr : np.array(gf_b(x_arr), 'float64').reshape(1,len(x_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_str = lambda x_k : np.array2string(x_k.reshape(len(x_k)), precision=3, separator=',')\n",
    "\n",
    "f_str = lambda x : \"{0:.4f}\".format(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputTable:    \n",
    "    def __init__(self):\n",
    "        self.table = pd.DataFrame([],columns=['k', 'x^k', 'f(x^k)', 'd^k', 'a^k', 'x^k+1'])\n",
    "    def add_row(self, k, xk, fxk, dk, ak, xkp):\n",
    "        self.table.loc[len(self.table)] = [k, np_str(xk), f_str(fxk.item()), np_str(dk), ak, np_str(xkp)]\n",
    "    def print_latex(self):\n",
    "        print(self.table.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A : Least Square Method with Steepest Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact Line Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BisectionMethod(f,epsilon, a=-100,b=100) :\n",
    "    iteration=0\n",
    "    while (b - a) >= epsilon:\n",
    "        x_1 = (a + b) / 2\n",
    "        fx_1 = f(x_1)\n",
    "        if f(x_1 + epsilon) <= fx_1:\n",
    "            a = x_1\n",
    "        else:\n",
    "            b = x_1\n",
    "        iteration+=1\n",
    "    x_star = (a+b)/2\n",
    "    return x_star\n",
    "\n",
    "def ExactLineSearch(f, x0, d, eps=0.0000001):\n",
    "    alpha = Symbol('alpha')\n",
    "    function_alpha = f(np.array(x0)+alpha*np.array(d))\n",
    "    f_alp = lambdify(alpha, function_alpha, 'numpy')\n",
    "    alp_star = BisectionMethod(f_alp, epsilon=eps)\n",
    "    return alp_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steepest Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepestDescentMethod(f, grad_f, x_0, epsilon):\n",
    "    xk = np.array(x_0).reshape(2,1)\n",
    "    k = 0\n",
    "    stop = False\n",
    "    output = OutputTable()\n",
    "    while(stop == False):\n",
    "        d = - np.transpose(grad_f(xk))\n",
    "        if(np.linalg.norm(d) < epsilon):\n",
    "            stop = True\n",
    "        else:\n",
    "            a = ExactLineSearch(f,xk,d)\n",
    "            xkp = xk + a*d\n",
    "            output.add_row(k, xk, f(xk), d, a, xkp)\n",
    "            k += 1\n",
    "            xk = xkp\n",
    "    output.add_row(k,xk,f(xk),d,None,np.array([]))\n",
    "    return xk, np.asscalar(f(xk)), output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xk = np.array([0,0]).reshape(2,1)\n",
    "xk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ws_a, fs_a, outputs_a = steepestDescentMethod(f_a, grad_fa, [0,0], 0.001)\n",
    "#ws_a, fs_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_b, fs_b, outputs_b = steepestDescentMethod(f_b, grad_fb, [0,0], 0.001)\n",
    "ws_b, fs_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B : Nonlinear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_data['x'])\n",
    "y_train = np.array(train_data['y'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(input_data,label_data,learning_rate=0.9,alpha=0.5,epsilon=0.001):\n",
    "    epsilon=epsilon\n",
    "    t=0\n",
    "    x_train=input_data.reshape(100,1)\n",
    "    y_train=label_data.reshape(100,1)\n",
    "    all_data=np.full((100, 1), -1)\n",
    "    x_train=np.concatenate((all_data,x_train),axis=1)\n",
    "    weight_first=np.random.rand(3,2)\n",
    "    weight_second=np.random.rand(1,4)#2 hidden units\n",
    "    h=np.random.rand(100,3)\n",
    "    H=np.random.rand(100,3)\n",
    "    o=np.random.rand(100,1)\n",
    "    O=np.random.rand(100,1)\n",
    "    sigma_output=np.random.rand(100,1)\n",
    "    sigma_hidden=np.random.rand(100,3)\n",
    "    Error_value=0\n",
    "    delta_big=np.random.rand(1,4)\n",
    "    delta_small=np.random.rand(3,2)\n",
    "    while(True): \n",
    "        np.random.shuffle(x_train)     \n",
    "        for p in range(100):\n",
    "            \n",
    "            for j in range(3):\n",
    "                sum_first=0\n",
    "                for k in range(2):\n",
    "                    \n",
    "                    sum_first=sum_first+((weight_first[j,k]*x_train[p,k]))\n",
    "                h[p,j]=sum_first\n",
    "                H[p,j] = 1/(1+np.exp(-h[p,j]))\n",
    "            \n",
    "                \n",
    "            all_data_2=np.full((100,1),-1)\n",
    "            all_data_2=np.concatenate((all_data_2,H),axis=1)\n",
    "            H_with_zero=all_data_2\n",
    "\n",
    "            for i in range(1):\n",
    "                sum_second=0\n",
    "                for j in range(4):\n",
    "                    sum_second=sum_second+weight_second[i,j]*H_with_zero[p,j]\n",
    "                o[p,i]=sum_second\n",
    "                O[p,i]=o[p,i]\n",
    "            \n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "            for i in range(1):\n",
    "                sigma_output[p,i]=y_train[p,i]-O[p,i]\n",
    "               \n",
    "            for j in range(3): \n",
    "                sum_third=0\n",
    "                for i in range(1):\n",
    "                    sum_third=sum_third+(weight_second[i,j]*sigma_output[p,i])\n",
    "               \n",
    "                sigma_hidden[p,j]=H[p,j]*(1-H[p,j])*sum_third\n",
    "                \n",
    "            for j in range(4):    \n",
    "                for i in range(1): \n",
    "                    delta_big[i,j]=learning_rate*sigma_output[p,i]*H_with_zero[p,j]\n",
    "                    weight_second[i,j]=weight_second[i,j]+delta_big[i,j]\n",
    "                    \n",
    "            for k in range(2):   \n",
    "                for j in range(3): \n",
    "                    \n",
    "                    delta_small[j,k]=learning_rate*sigma_hidden[p,j]*x_train[p,k]\n",
    "                    weight_first[j,k]=weight_first[j,k]+delta_small[j,k]\n",
    "                    \n",
    "        \n",
    "        summation = 0  #variable to store the summation of differences\n",
    "        n = len(y_train) #finding total number of items in list\n",
    "        for i in range (0,n):  #looping through each element of the list\n",
    "            difference = O[i] - y_train[i]  #finding the difference between observed and predicted value\n",
    "            squared_difference = difference**2  #taking square of the differene \n",
    "            summation = summation + squared_difference  #taking a sum of all the differences\n",
    "        MSE = summation/2  #dividing summation by 2\n",
    "        print( \"The Mean Square Error is: \" , MSE)\n",
    "        learning_rate=learning_rate*alpha\n",
    "        t=t+1\n",
    "        \n",
    "        if learning_rate<epsilon:\n",
    "            break\n",
    "    return weight_first,weight_second,MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Square Error is:  [7.4494729e+52]\n",
      "The Mean Square Error is:  [1.60450185e+53]\n",
      "The Mean Square Error is:  [2508914.21113687]\n",
      "The Mean Square Error is:  [2163073.07438283]\n",
      "The Mean Square Error is:  [2447429.08263533]\n",
      "The Mean Square Error is:  [2986844.92771541]\n",
      "The Mean Square Error is:  [3764765.14688899]\n",
      "The Mean Square Error is:  [4284833.63811607]\n",
      "The Mean Square Error is:  [4284279.57421693]\n",
      "The Mean Square Error is:  [4190867.17997067]\n"
     ]
    }
   ],
   "source": [
    "weight_1,weight_2,Error=backpropagation(x_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
